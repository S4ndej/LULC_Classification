[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LULC Classification",
    "section": "",
    "text": "Celem badania jest budowa optymalnego modelu klasyfikacyjnego za pomocą wybranych algorytmów uczenia maszynowego. Jego zadaniem będzie klasyfikowanie wykorzystania gruntów na obrazach geoprzestrzennych."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#cel-badawczy",
    "href": "index.html#cel-badawczy",
    "title": "LULC Classification",
    "section": "",
    "text": "Celem badania jest budowa optymalnego modelu klasyfikacyjnego za pomocą wybranych algorytmów uczenia maszynowego. Jego zadaniem będzie klasyfikowanie wykorzystania gruntów na obrazach geoprzestrzennych."
  },
  {
    "objectID": "index.html#informacje-o-zbiorze",
    "href": "index.html#informacje-o-zbiorze",
    "title": "LULC Classification",
    "section": "Informacje o zbiorze",
    "text": "Informacje o zbiorze\nW Projekcie używałem danych pochodzących z huggingface. Zbiór danych przedstawia zdjęcia satelitarne zrobione przez Sentinel-2. Zbiór zawiera 27000 zdjęć 10 klas Użytkowanie Gruntów i Pokrycie Terenu (Land Use and Land Cover). Zbiór został już podzielony w proporcji na treningowy (80%) - 21600 zdjęć, walidacyjny (10%) - 2700 zdjęć, testowy (10%) - 2700 zdjęć.\n\nWczytanie danych\n\n\nCode\ntrain &lt;- read_parquet(\"train-00000-of-00001.parquet\", as_data_frame = TRUE)\nval &lt;- read_parquet(\"validation-00000-of-00001.parquet\", as_data_frame = TRUE)\ntest &lt;- read_parquet(\"test-00000-of-00001.parquet\", as_data_frame = TRUE)\n\n\n\n\nZamienienie danych na katalogi\n\n\nCode\n# Class name for each class\nclass_names &lt;- c(\"Forest\", \"River\", \"Highway\", \"AnnualCrop\", \"SeaLake\", \n                 \"HerbaceousVegetation\", \"Industrial\", \"Residential\", \n                 \"PermanentCrop\", \"Pasture\")\n\n# Main directory for training data\nTrain &lt;- \"Train\"\nif (!dir.exists(Train)) {\n  dir.create(Train)\n}\n\n# Create directories for each class\nfor (name in class_names) {\n  class_dir &lt;- file.path(Train, name)\n  if (!dir.exists(class_dir)) {\n    dir.create(class_dir)\n  }\n}\n\n# Process each image\nfor (i in 1:length(train$image$bytes)) {\n  binary_data &lt;- as.raw(train$image$bytes[[i]])\n  tmp_file &lt;- tempfile()\n  writeBin(binary_data, tmp_file)\n  obraz &lt;- readJPEG(tmp_file)\n  file.remove(tmp_file)\n  \n  # Get class label and name (adjusting for zero-based indexing)\n  class_label &lt;- train$label[i]\n  class_name &lt;- class_names[class_label + 1]\n  \n  # Create output file path\n  output_file &lt;- file.path(Train, class_name, paste0(\"image_\", i, \".jpg\"))\n  \n  # Write image to the output file\n  writeJPEG(obraz, output_file)\n}\n\nVal &lt;- \"Val\"\nif (!dir.exists(Val)) {\n  dir.create(Val)\n}\n\nfor (name in class_names) {\n  class_dir &lt;- file.path(Val, name)\n  if (!dir.exists(class_dir)) {\n    dir.create(class_dir)\n  }\n}\nfor (i in 1:length(val$image$bytes)) {\n  binary_data &lt;- as.raw(val$image$bytes[[i]])\n  tmp_file &lt;- tempfile()\n  writeBin(binary_data, tmp_file)\n  obraz &lt;- readJPEG(tmp_file)\n  file.remove(tmp_file)\n  class_label &lt;- val$label[i]\n  class_name &lt;- class_names[class_label + 1]\n\n  output_file &lt;- file.path(Val, class_name, paste0(\"image_\", i, \".jpg\"))\n  writeJPEG(obraz, output_file)\n}\n\nTest &lt;- \"Test\"\nif (!dir.exists(Test)) {\n  dir.create(Test)\n}\n\nfor (name in class_names) {\n  class_dir &lt;- file.path(Test, name)\n  if (!dir.exists(class_dir)) {\n    dir.create(class_dir)\n  }\n}\nfor (i in 1:length(test$image$bytes)) {\n  binary_data &lt;- as.raw(test$image$bytes[[i]])\n  tmp_file &lt;- tempfile()\n  writeBin(binary_data, tmp_file)\n  obraz &lt;- readJPEG(tmp_file)\n  file.remove(tmp_file)\n  class_label &lt;- test$label[i]\n  class_name &lt;- class_names[class_label + 1]\n  output_file &lt;- file.path(Test, class_name, paste0(\"image_\", i, \".jpg\"))\n  writeJPEG(obraz, output_file)\n}\n\n\n\n\nRozkład klas\n\n\n\n\n\nKlasa\nTreningowy\nWalidacyjny\nTestowy\n\n\n\n\nForest\n2400\n300\n300\n\n\nRiver\n2000\n250\n250\n\n\nHighway\n2000\n250\n250\n\n\nAnnualCrop\n2400\n300\n300\n\n\nSeaLake\n2400\n300\n300\n\n\nHerbaceousVegetation\n2400\n300\n300\n\n\nIndustrial\n2000\n250\n250\n\n\nResidential\n2400\n300\n300\n\n\nPermanentCrop\n2000\n250\n250\n\n\nPasture\n1600\n200\n200\n\n\n\n\n\n\n\nPrzykładowe obrazy\n\n\n\n\n\n\n\nOkreślenie miary\nZa miarę sukcesu przyjmuję:\n\nAccuracy - dokładność, jak dobrze model klasyfikuje dane,\nAUC - pole pod krzywą ROC, jak dobrze model rozróżnia klasy,\n\n\n\nLinki do projektów w Kaggle\nAAO_Projekt\nAAO_Projekt2\nAA0_Projekt3\nAA0_Projekt4\nAA0_Projekt5\nAA0_Projekt_test"
  },
  {
    "objectID": "index.html#modelowanie",
    "href": "index.html#modelowanie",
    "title": "LULC Classification",
    "section": "Modelowanie",
    "text": "Modelowanie\n\nCallback\nCallback to specjalna funkcja, która jest używana na różnych etapach uczenia do monitorowania procesu trenowania modelu. Oto callbacki jakich używałem:\n\n\nCode\ncallbacks_list &lt;- list(\n  callback_early_stopping(monitor = \"val_loss\", patience = 10),\n  callback_reduce_lr_on_plateau(monitor = \"val_loss\", factor = 0.1, patience = 5)\n)\n\n\ncallback_early_stopping - zatrzymuje trening jeśli val_loss nie poprawi się przez 10 epok\ncallback_reduce_lr_on_plateau - zmienia współczynnik uczenia o 0.1 jeśli val_loss nie poprawi się przez 5 epok\n\n\nPrzygotowanie danych\nGeneruję dane treningowe, walidacyjne oraz treningowe za pomocą generatorów.\n\n\nCode\ntrain_data_gen &lt;- image_data_generator(rescale = 1/255)\nval_data_gen &lt;- image_data_generator(rescale = 1/255)\ntest_data_gen &lt;- image_data_generator(rescale = 1/255)\n\ntrain_generator1 &lt;- flow_images_from_directory(\n  file.path(\"Train\"),\n  train_data_gen,\n  target_size = c(64, 64),\n  batch_size = 32,\n  class_mode = \"categorical\"\n)\n\n\n\n\nCode\nval_generator1 &lt;- flow_images_from_directory(\n  file.path(\"Val\"),\n  val_data_gen,\n  target_size = c(64, 64),\n  batch_size = 32,\n  class_mode = \"categorical\"\n)\n\ntest_generator1 &lt;- flow_images_from_directory(\n  file.path(\"Test\"),\n  test_data_gen,\n  target_size = c(64, 64),\n  batch_size = 32,\n  class_mode = \"categorical\"\n)\n\n\nimage_data_generator() jest funkcją służącą do tworzenia generatora obrazków, który wykonuje ich przekształcenia. W tym przypadku rescale = 1/255 jest to funkcja, która normalizuje piksele obrazów (przeskalowuje wartości pikseli w obrazach z [0,255] do [0,1], co jest standardową praktyką w przetwarzaniu obrazów do trenowania modeli). Następnie za pomocą flow_images_from_directory generuje serie (ang. baches) danych z obrazów z katalogów Train, Val, Test używając wcześniej zdefiniowanego generatora ustawiając rozmiar obrazów na 64x64, rozmiar serii (liczba obrazów w jednej serii) na 32 oraz tryb klasyfikacji wieloklasowej.\n\n\nArgumentacja\nPrzeprowadziłem argumentację obrazów za pomocą funkcji image_data_generator():\n\n\nCode\ndatagen &lt;- image_data_generator(\n  rotation_range = 40,\n  width_shift_range = 0.2,\n  height_shift_range = 0.2,\n  shear_range = 0.2,\n  zoom_range = 0.2,\n  channel_shift_range = 0.2,\n  fill_mode = \"nearest\",\n  horizontal_flip = TRUE,\n  vertical_flip = FALSE,\n  rescale = 1/255,\n)\n\n\n\nrotation_range = 40 - obraz może być losowo obracany o 40 stopni,\nwidth_shift_range = 0.2 - obraz może być losowo przesuwany wzdłuż osi szerokości o 20%,\nheight_shift_range = 0.2 - obraz może być losowo przesuwany wzdłuż osi wysokości o 20% ,\nshear_range = 0.2 - obraz może być losowo ścinany o 20%,\nzoom_range = 0.2 - obraz może być losowo przybliżany lub oddalany o 20%,\nchannel_shift_range = 0.2 - intensywność kanałów może być losowo przesunięta o 20%,\nfill_mode = \"nearest\" - po różnych operacjach przekształceń wypełnia piksele najbliższym sąsiadem,\nhorizontal_flip = TRUE - losowe odbicie poziome obrazu,\nvertical_flip = FALSE - losowe odbicie pionowe obrazu,\nrescale = 1/255 - normalizacja pikseli.\n\n\n\nCode\ntrain_generator2 &lt;- flow_images_from_directory(\n  file.path(\"Train\"),\n  datagen,\n  target_size = c(64, 64),\n  batch_size = 32,\n  class_mode = \"categorical\"\n)\n\n\nTworze generatora z argumentowaniami obrazów.\n\n\nParametry modelów\nDo tworzenia modelów będę używał następujących funkcji:\n\nkeras_model_sequential() - tworzy nowy, pusty model sekwencyjny do którego będą dodawane nowe warstwy,\nlayer_conv_2d() - dodaje warstwę konwolucyjną,\n\nfilters - liczba filtrów w warstwie konwolucyjnej (wielokrotności 2),\nkernel_size - rozmiar filtra (3x3),\nactivation - funkcja aktywacji (relu),\ninput_shape - kształt danych wejściowych (64x64x3),\nkernel_regularizer - dodaje regularyzator, który dodaje karę do funkcji kosztu proporcjonalną do kwadratu wartości wag,\n\nlayer_max_pooling_2d() - dodaje warstwę maksymalnego próbkowania,\n\npool_size - rozmiar okna próbkowania, które zmniejszają rozmiar obrazu (2x2),\n\nlayer_flatten() - przekształca dane wyjściowe z poprzednich warstw do jednowymiarowego wektora, aby można było je podać do warstwy gęstej,\nlayer_dense() - dodawanie warstwy gęstej ,\n\nunits - liczba neuronów w warstwie (wielokrotności 2),\nactivation - funkcja aktywacji (relu),\nunits = 10, activation = \"softmax\" - liczba neuronów odpowiadająca liczbie klas, funkcja aktywacji softmax, która przekształca wyjście w prawdopodobieństwo przynależności do poszczególnych klas,\n\nlayer_dropout() - określa częstotliwość z jaką jednostki w warstwie będą wyłączane podczas treningu (25%, 50%),\nlayer_batch_normalization() - normalizuje aktywacje z poprzedniej warstwy, pomaga w stabilizacji i przyśpieszeniu procesu treningu,\n\n\n\nParametry kompilacji\n\nloss = 'categorical_crossentropy': Funkcja straty, która jest używana do oceny błędu między rzeczywistymi a przewidywanymi wynikami.\noptimizer = optimizer_adam(): Algorytm optymalizacji Adam, który dostosowuje tempo uczenia podczas trenowania.\noptimizer = optimizer_nadam(): Jest rozszerzeniem algorytmu Adam.\nmetrics = c('accuracy', 'AUC'): Metryka, którą chcemy monitorować podczas trenowania, tutaj jest to dokładność oraz Area Under the Curve.\n\n\n\nModel1\nTworzę 2 modele o tych samych parametrach: Model1Basic, Model1Argumented.\n\n\nCode\nmodel1Basic &lt;- model1Argumented  &lt;- keras_model_sequential() %&gt;%\n  layer_conv_2d(filters = 16, kernel_size = c(3, 3), activation = 'relu', input_shape = c(64, 64, 3)) %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = 'relu') %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = 'relu') %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_flatten() %&gt;%\n  layer_dense(units = 16, activation = 'relu') %&gt;%\n  layer_dense(units = 10, activation = 'softmax')\n\n\nmodel1Basic %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_nadam(),\n  metrics = c('accuracy', 'AUC')\n)\n\nmodel1Argumented %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_nadam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\nTe modele mają 60,634 parametrów.\n\nTrenowanie Model1Basic\n\n\nCode\nhistory1Basic &lt;- model1Basic %&gt;% fit(\n  train_generator1,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list\n)\n\nplot(history1Basic)\n\n\n\n\n\nHistoria trenowania Model1Basic\n\n\n\n\nCode\nmodel1Basic %&gt;% evaluate(train_generator1, steps =  as.integer(nrow(train) / 32))\nmodel1Basic %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model1Basic, filepath=\"models/model1Basic\")\n\n\n\n\n\n\n\n\nresult_train_model1Basic\nresult_val_model1Basic\n\n\n\n\nloss\n0.1610972\n0.3978839\n\n\naccuracy\n0.9482408\n0.8671875\n\n\nauc\n0.9980304\n0.9883901\n\n\n\n\n\nModel1Basic został wytrenowany na obrazach bez argumentacji. Model przestał się poprawiać według callbacka po około 55 epokach. Strata (loss) jest znacznie mniejszy na zbiorze treningowym co może oznaczać przeuczenie (overfitting). Dokładność na zbiorze testowym wyniosła 94.82%, natomiast na zbiorze walidacyjnym 86.72%, co również sugeruje, że model jest przeuczony. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model dobrze rozróżnia klasy.\n\n\nTrenowanie Model1Argumented\n\n\nCode\nhistory1Argumented &lt;- model1Argumented %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n    callbacks = callbacks_list\n)\n\nplot(history1Argumented)\n\n\n\n\n\nHistoria trenowania Model1Argumented\n\n\n\n\nCode\nmodel1Argumented %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel1Argumented %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model1Argumented, filepath=\"models/model1Argumented\")\n\n\n\n\n\n\n\n\nresult_train_model1Argumented\nresult_val_model1Argumented\n\n\n\n\nloss\n0.5960687\n0.4394066\n\n\naccuracy\n0.8149537\n0.8623512\n\n\nauc\n0.9767833\n0.9852272\n\n\n\n\n\nModel1Argumented został wytrenowany na obrazach z argumentacją. Model przestał się poprawiać według callbacka po około 12 epokach. Strata jest znacznie mniejsza na zbiorze walidacyjnym co może oznaczać, że model dobrze generalizuje i nie jest przeuczony. Dokładność na zbiorze testowym wyniosła 81.5%, natomiast na zbiorze walidacyjnym 86.24%, co również sugeruje, że model nie jest przeuczony i dobrze generalizuje. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model dobrze rozróżnia klasy.\n\n\nWnioski\nModel1Basic pokazuje lepsze wyniki metryk zarówno na zborze treningowym jak i walidacyjnym, co sugeruje, że jest bardziej skuteczny w klasyfikacji obrazów, ale jest widocznie przeuczony. Model1Argumented może mieć większy potencjał do generalizacji na nowe, nieznane dane, gdyż został zbudowany z argumentacją.\n\n\n\nModel2\nTworzę 2 modele o tych samych parametrach: Model2Basic, Model2Argumented.\n\n\nCode\nmodel2Basic &lt;- model2Argumented  &lt;- keras_model_sequential() %&gt;%\n  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = 'relu', input_shape = c(64, 64, 3)) %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = 'relu') %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = 'relu') %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_flatten() %&gt;%\n  \n  layer_dense(units = 512, activation = 'relu') %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_dropout(rate = 0.5) %&gt;%\n  \n  layer_dense(units = 10, activation = 'softmax')\n\nmodel2Basic %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\nTe modele mają 2,461,130 parametrów.\n\n\nCode\nmodel2Argumented %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\n\nTrenowanie Model2Basic\n\n\nCode\nhistory2Basic &lt;- model2Basic %&gt;% fit(\n  train_generator1,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list  \n)\nplot(history2Basic)\n\n\n\n\n\nHistoria trenowania Model2Basic\n\n\n\n\nCode\nmodel2Basic %&gt;% evaluate(train_generator1, steps =as.integer(nrow(train) / 32))\nmodel2Basic %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model2Basic, filepath=\"models/model2Basic\")\n\n\n\n\n\n\n\n\nresult_train_model2Basic\nresult_val_model2Basic\n\n\n\n\nloss\n0.0356646\n0.2806661\n\n\naccuracy\n0.9895833\n0.9151786\n\n\nauc\n0.9998043\n0.9916943\n\n\n\n\n\nModel2Basic został wytrenowany na obrazach bez argumentacji. Model przestał się poprawiać według callbacka po około 34 epokach. Strata jest bardzo niska na zbiorze treningowym, ale nieco wyższa na zbiorze walidacyjnym co może oznaczać przeuczenie, ale różnica nie jest dramatycznie wysoka. Dokładność na zbiorze testowym wyniosła 98.96%, natomiast na zbiorze walidacyjnym 91.52%, co sugeruje, że model dobrze klasyfikuje dane na których był trenowany, ale nieco gorzej generalizuje. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model dobrze rozróżnia klasy.\n\n\nTrenowanie Model2Argumented\n\n\nCode\nhistory2Argumented &lt;- model2Argumented %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n    callbacks = callbacks_list\n)\n\nplot(history2Argumented)\n\n\n\n\n\nHistoria trenowania Model2Argumented\n\n\n\n\nCode\nmodel2Argumented %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel2Argumented %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model2Argumented, filepath=\"models/model2Argumented\")\n\n\n\n\n\n\n\n\nresult_train_model2Argumented\nresult_val_model2Argumented\n\n\n\n\nloss\n0.4655367\n0.4346156\n\n\naccuracy\n0.8669444\n0.8861607\n\n\nauc\n0.9828715\n0.9833450\n\n\n\n\n\nModel2Argumented został wytrenowany na obrazach z argumentacją. Model przestał się poprawiać według callbacka po około 12 epokach. Strata jest nieco wyższa zbiorze treningowy niż na zbiorze walidacyjnym co może oznaczać że model nie jest przeuczony. Dokładność na zbiorze testowym wyniosła 86.69%, natomiast na zbiorze walidacyjnym 88.62%, co sugeruje, że model w miare dobrze klasyfikuje dane na których był trenowany, lepiej generalizuje. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model dobrze rozróżnia klasy.\n\n\nWnioski\nModel2Basic wykazuje lepszą wydajność pod względem wszystkich metryk, jednak model jest przeuczony. Model2Argumented mimo mniejszej skuteczność dopasowania może lepiej generalizować.\n\n\n\nModel3\nTworzę 2 modele o tych samych parametrach: Model3, ale w Model4 dodatkowo dodaję regularyzację.\n\n\nCode\nmodel3 &lt;- keras_model_sequential() %&gt;%\n  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = 'relu', input_shape = c(64, 64, 3)) %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = 'relu') %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = 'relu') %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_conv_2d(filters = 256, kernel_size = c(3, 3), activation = 'relu') %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_flatten() %&gt;%\n  \n  layer_dense(units = 512, activation = 'relu') %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_dropout(rate = 0.5) %&gt;%\n  \n  layer_dense(units = 256, activation = 'relu') %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_dropout(rate = 0.5) %&gt;%\n  \n  layer_dense(units = 10, activation = 'softmax')\n\nmodel3 %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\n\n\nCode\nmodel4 &lt;- keras_model_sequential() %&gt;%\n  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = 'relu', input_shape = c(64, 64, 3),\n                kernel_regularizer = regularizer_l2(0.01)) %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = 'relu',\n                kernel_regularizer = regularizer_l2(0.01)) %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = 'relu',\n                kernel_regularizer = regularizer_l2(0.01)) %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_conv_2d(filters = 256, kernel_size = c(3, 3), activation = 'relu',\n                kernel_regularizer = regularizer_l2(0.01)) %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%\n  layer_dropout(rate = 0.25) %&gt;%\n  \n  layer_flatten() %&gt;%\n  \n  layer_dense(units = 512, activation = 'relu',\n              kernel_regularizer = regularizer_l2(0.01)) %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_dropout(rate = 0.5) %&gt;%\n  \n  layer_dense(units = 256, activation = 'relu',\n              kernel_regularizer = regularizer_l2(0.01)) %&gt;%\n  layer_batch_normalization() %&gt;%\n  layer_dropout(rate = 0.5) %&gt;%\n  \n  layer_dense(units = 10, activation = 'softmax')\n\nmodel4 %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(learning_rate = 0.0001),\n  metrics = c('accuracy', 'AUC')\n)\n\n\nTe modele mają 1,052,106 parametrów.\n\nTrenowanie Model3\n\n\nCode\nhistory5 &lt;- model3 %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\ncallbacks = callbacks_list\n)\n\nplot(history5)\n\n\n\n\n\nHistoria trenowania Model3\n\n\n\n\nCode\nmodel3 %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel3 %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model3, filepath=\"models/model3\")\n\n\n\n\n\n\n\n\nresult_train_model3\nresult_val_model3\n\n\n\n\nloss\n0.2708846\n0.3090858\n\n\naccuracy\n0.9036111\n0.8947173\n\n\nauc\n0.9945973\n0.9925712\n\n\n\n\n\nModel3 został wytrenowany na obrazach z argumentacją. Model przestał się poprawiać według callbacka po około 45 epokach. Strata jest nieznacznie wyższa na zbiorze walidacyjnym co może oznaczać, że jest nieznacznie przeuczony. Dokładność na zbiorze testowym wyniosła 90.36%, natomiast na zbiorze walidacyjnym 89.47%, co sugeruje, że model jest nieznacznie przeuczony i dobrze generalizuje. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model dobrze rozróżnia klasy.\n\n\nTrenowanie Model4\n\n\nCode\nhistory6 &lt;- model4 %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list\n)\n\nplot(history6)\n\n\n\n\n\nHistoria trenowania Model4\n\n\n\n\n\n\n\n\nresult_train_model4\nresult_val_model4\n\n\n\n\nloss\n0.7933937\n0.8020640\n\n\naccuracy\n0.8313426\n0.8351935\n\n\nauc\n0.9843642\n0.9833555\n\n\n\n\n\nModel4 został wytrenowany na obrazach z argumentacją. Model przestał się poprawiać według callbacka po około 38 epokach. Strata jest nieznacznie wyższa na zbiorze walidacyjnym co może oznaczać, że jest nieznacznie przeuczony. Dokładność na zbiorze testowym wyniosła 83.13%, natomiast na zbiorze walidacyjnym 83.52%, co sugeruje, że model nie jest przeuczony i dobrze generalizuje. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model dobrze rozróżnia klasy.\n\n\nWnioski\nDodanie regularyzacji pogorszyło metryki Model4 względem Model3.\n\n\n\nVGG16\nVGG16 jest to jeden z popularnych modeli oparty na konwolucyjnych sieciach neuronowych. Tworzę 2 modele:\n\nModel5VGG jest wstępnie uczony (wagi są wstępnie wytrenowane na ImageNet), nie zachowuje w pełni połączonych warstw.\nModel6VGG nie jest wstępnie uczony (wagi są losowe) oraz zachowuje w pełni połączone warstwy.\n\n\n\nCode\nconv_baseVGG1 &lt;- application_vgg16(\n  weights = \"imagenet\",\n  include_top = FALSE,\n  input_shape = c(64,64, 3)\n)\ncat(\"Liczba tensorów poddawanych uczeniu przez zamrożeniem:\", length(model5VGG$trainable_weights), \"\\n\")\nfreeze_weights(conv_baseVGG1)\n\ncat(\"Liczba tensorów poddawanych ucznieu po zamrożeniu wag:\", length(model5VGG$trainable_weights), \"\\n\")\n\n\nLiczba tensorów poddawanych uczeniu przez zamrożeniem: 30\nLiczba tensorów poddawanych ucznieu po zamrożeniu wag: 4\n\n\nCode\nmodel5VGG &lt;- keras_model_sequential() %&gt;%\n  conv_baseVGG1 %&gt;%\n  layer_flatten() %&gt;%\n  layer_dense(units = 256, activation = \"relu\") %&gt;%\n layer_dropout(rate = 0.5)%&gt;%\n  layer_dense(units = 10, activation = \"softmax\")\n\nmodel5VGG%&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC'))\n\n\n\n\nCode\nmodel6VGG &lt;- application_vgg16(\n  weights = NULL,  \n  include_top = TRUE,  \n  classes = 10,  \n  input_shape = c(64, 64, 3)  \n)\nmodel6VGG %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\nTe modele mają 14,714,688 parametrów.\n\nTrenowanie Model5VGG\n\n\nCode\nhistory7 &lt;- model5VGG %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list\n)\nplot(history7)\n\n\n\n\n\nHistoria trenowania Model5VGG\n\n\n\n\nCode\nmodel5VGG %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel5VGG %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model5VGG, filepath=\"models/model5VGG\")\n\n\n\n\n\n\n\n\nresult_train_model5VGG\nresult_val_model5VGG\n\n\n\n\nloss\n0.4470802\n0.4394602\n\n\naccuracy\n0.8416666\n0.8601190\n\n\nauc\n0.9878412\n0.9863861\n\n\n\n\n\nModel5VGG został wytrenowany na obrazach z argumentacją. Model przestał się poprawiać według callbacka po około 45 epokach. Strata jest na zbiorze treningowy jest bardzo zbliżona do straty na zbiorze walidacyjnym. Dokładność na zbiorze testowym wyniosła 84.17%, natomiast na zbiorze walidacyjnym 86.01%, co sugeruje, że model w miarę dobrze klasyfikuje dane na których był trenowany, lepiej generalizuje. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model dobrze rozróżnia klasy.\n\n\nTrenowanie Model6VGG\n\n\nCode\nhistory8 &lt;- model6VGG %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list\n)\nplot(history8)\n\n\n\n\n\nHistoria trenowania Model6VGG\n\n\n\n\nCode\nmodel6VGG %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel6VGG %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model6VGG, filepath=\"models/model6VGG\")\n\n\n\n\n\n\n\n\nresult_train_model6VGG\nresult_val_model6VGG\n\n\n\n\nloss\n2.2947874\n2.2948823\n\n\naccuracy\n0.1111111\n0.1116071\n\n\nauc\n0.5349795\n0.5348256\n\n\n\n\n\nModel6VGG został wytrenowany na obrazach z argumentacją. Model przestał się poprawiać według callbacka po około 45 epokach. Strata jest na obu zbiorach jest wysoka, co sugeruje, że model ma trudność dopasowywania się do danych. Dokładność na zbiorze testowym wyniosła 11.11%, natomiast na zbiorze walidacyjnym 11.16%, co sugeruje, że model ma bardzo niską dokładność, jest zbliżona do zgadywania. Wartości AUC są bliskie 0.5 w obu przypadkach, co oznacza że model nie ma zdolności do rozróżniania klas.\n\n\nWnioski\nModel5VGG jest lepszy we wszystkich metrykach.\n\n\n\nDenseNet121\nDenseNet121 to popularna architektura głębokich sieci neuronowych do zadań związanych z rozpoznawanie obrazu. Zakłada ona że każda warstwa otrzymuje nie tylko wyjście poprzedniej warstwy, ale także wszystkich poprzednich. Tworzę dwa modele:\n\nModel7DN121: Wagi są wyuczone na ImageNet oraz bez górnych warstw,\nModel8DN121: Wagi są losowo przypisywane oraz z górnymi warstwami.\n\n\n\nCode\nconv_baseDN121 &lt;- application_densenet121(\n  weights = \"imagenet\",\n  include_top = FALSE,\n  input_shape = c(64, 64, 3)\n)\nfreeze_weights(conv_baseDN121)\n\nmodel7DN121 &lt;- keras_model_sequential() %&gt;%\n  conv_baseDN121 %&gt;%\n  layer_flatten() %&gt;%\n  layer_dense(units = 256, activation = \"relu\") %&gt;%\n  layer_dropout(rate = 0.5) %&gt;%\n  layer_dense(units = 10, activation = \"softmax\")\n\nmodel7DN121 %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\n\n\nCode\nmodel8DN121_2 &lt;- application_densenet121(\n  weights = NULL,\n  include_top = TRUE,\n  classes = 10,\n  input_shape = c(64, 64, 3)\n)\nmodel8DN121_2 %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\nTe modele mają 7,037,504 parametrów.\n\nTrenowanie Model7DN121\n\n\nCode\nhistory9 &lt;- model7DN121 %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list\n)\nplot(history9)\n\n\n\n\n\nHistoria trenowania Model7DN121\n\n\n\n\nCode\nmodel7DN121 %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel7DN121 %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model7DN121, filepath=\"models/model7DN121\")\n\n\n\n\n\n\n\n\nresult_train_model7DN121\nresult_val_model7DN121\n\n\n\n\nloss\n0.3552384\n0.3565677\n\n\naccuracy\n0.8759722\n0.8794643\n\n\nauc\n0.9913244\n0.9904802\n\n\n\n\n\nModel7DN121 został wytrenowany na obrazach z argumentacją. Model przestał się poprawiać według callbacka po około 58 epokach. Strata jest na obu zbiorach jest stosunkowo niska, co sugeruje, że model ma nie trudność dopasowywania się do danych. Dokładność na zbiorze testowym wyniosła 87.6%, natomiast na zbiorze walidacyjnym 87.95%, co sugeruje, że model radzi sobie stosunkowo dobrze z przewidywaniem klas. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model ma zdolności do różnicowania klas.\n\n\nTrenowanie Model8DN121\n\n\nCode\nhistory10 &lt;- model8DN121_2 %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list\n)\nplot(history10)\n\n\n\n\n\nHistoria trenowania Model8DN121_2\n\n\n\n\nCode\nmodel8DN121_2 %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel8DN121_2 %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model8DN121_2, filepath=\"models/model8DN121_2\")\n\n\n\n\n\n\n\n\nresult_train_model8DN121_2\nresult_val_model8DN121_2\n\n\n\n\nloss\n0.0843645\n0.1490799\n\n\naccuracy\n0.9716667\n0.9512649\n\n\nauc\n0.9992834\n0.9971818\n\n\n\n\n\nModel8DN121_2 został wytrenowany na obrazach z argumentacją. Model przestał się poprawiać według callbacka po około 38 epokach. Strata jest na obu zbiorach jest niska, co sugeruje, że model ma nie trudność dopasowywania się do danych. Dokładność na zbiorze testowym wyniosła 97.17%, natomiast na zbiorze walidacyjnym 95.13%, co sugeruje, że model radzi sobie bardzo dobrze z przewidywaniem klas. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model ma zdolności do różnicowania klas.\n\n\nWnioski\nModel8DN121_2 jest wyraźnie lepszy i bardziej efektywny niż Model7DN121, mimo że może występować nieznaczne przeuczenie.\n\n\n\nEfficientNetB2\nEfficientNet to rodzina modeli konwolucyjnych sieci neuronowych opracowana przez Google, wykorzystuje technikę skalowania współczynników, aby efektywnie skalować głębokość, szerokość i rozdzielczość sieci, co wpływa na lepsze wykorzystanie zasobów obliczeniewych i lepsze klasyfikacji.\nTworzę 3 modele:\n\nModel9EFB2: Wagi są losowo przypisywane oraz z górnymi warstwami, dalej jest trenowany na argumentowanym zbiorze obrazów,\nModel10EFB2: Wagi są losowo przypisywane oraz z górnymi warstwami, dalej jest trenowany na nieargumentowanym zbiorze obrazów,\nModel12EFB2: Wagi są losowo przypisywane oraz z górnymi warstwami, dalej jest trenowany na nieargumentowanym zbiorze obrazów możliwie do 100 epok, bez callbacku.\n\n\n\nCode\nmodel9EFB2 &lt;- application_efficientnet_b2( \n  weights = NULL,\n  include_top = TRUE,\n  classes = 10,\n  input_shape = c(64, 64, 3)\n)\nmodel9EFB2 %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\n\n\nCode\nmodel10EFB2 &lt;- application_efficientnet_b2( \n  weights = NULL,\n  include_top = TRUE,\n  classes = 10,\n  input_shape = c(64, 64, 3)\n)\nmodel10EFB2 %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\nmodel12EFB2 &lt;- application_efficientnet_b2( \n  weights = NULL,\n  include_top = TRUE,\n  classes = 10,\n  input_shape = c(64, 64, 3)\n)\nmodel12EFB2 %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy', 'AUC')\n)\n\n\nTe modele mają 10.2M parametrów.\n\nTrenowanie Model9EFB2\n\n\nCode\nhistory10 &lt;- model9EFB2 %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list\n)\nplot(history10)\n\n\n\n\n\nCode\nmodel9EFB2 %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel9EFB2 %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model9EFB2, filepath=\"models/model9EFB2\")\n\n\n\n\n\n\n\n\nresult_train_model9EFB2\nresult_val_model9EFB2\n\n\n\n\nloss\n0.1265306\n0.1511478\n\n\naccuracy\n0.9565278\n0.9445685\n\n\nauc\n0.9985757\n0.9981059\n\n\n\n\n\nModel9EFB2 przestał się poprawiać według callbacka po około 53 epokach. Strata jest na obu zbiorach jest stosunkowo niska, co sugeruje, że model ma nie trudność dopasowywania się do danych. Dokładność na zbiorze testowym wyniosła 95.65%, natomiast na zbiorze walidacyjnym 94.46%, co sugeruje, że model radzi sobie bardzo dobrze z przewidywaniem klas. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model ma zdolności do różnicowania klas.\n\n\nTrenowanie Model10EFB2\n\n\nCode\nhistory11 &lt;- model10EFB2 %&gt;% fit(\n  train_generator1,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32),\n  callbacks = callbacks_list\n)\nplot(history11)\n\n\n\n\n\nHistoria trenowania Model10EFB2\n\n\n\n\nCode\nmodel10EFB2 %&gt;% evaluate(train_generator1, steps = as.integer(nrow(train) / 32))\nmodel10EFB2 %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model10EFB2, filepath=\"models/model10EFB2\")\n\n\n\n\n\n\n\n\nresult_train_model10EFB2\nresult_val_model10EFB2\n\n\n\n\nloss\n0.1040396\n0.5876755\n\n\naccuracy\n0.9869907\n0.8649554\n\n\nauc\n0.9950755\n0.9753602\n\n\n\n\n\nModel10EFB2 przestał się poprawiać według callbacka po około 39 epokach. Strata jest bardzo niska na zbiorze treningowym, ale wyższa na zbiorze walidacyjnym co może oznaczać przeuczenie. Dokładność na zbiorze testowym wyniosła 98.7%, natomiast na zbiorze walidacyjnym 86.5%, co sugeruje, że model radzi sobie bardzo dobrze z przewidywaniem klas na zbiorze testowym, ale ma gorszą generalizację. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model ma zdolności do różnicowania klas.\n\n\nTrenowanie Model12EFB2\n\n\nCode\nhistory13 &lt;- model12EFB2 %&gt;% fit(\n  train_generator2,\n  steps_per_epoch = as.integer(nrow(train) / 32),\n  epochs = 100,\n  validation_data = val_generator1,\n  validation_steps = as.integer(nrow(val) / 32)\n)\nplot(history13)\n\n\n\n\n\nHistoria trenowania Model12EFB2\n\n\n\n\nCode\nmodel12EFB2 %&gt;% evaluate(train_generator2, steps = as.integer(nrow(train) / 32))\nmodel12EFB2 %&gt;% evaluate(val_generator1, steps = as.integer(nrow(val) / 32))\nsave_model_hdf5(model12EFB2, filepath=\"models/model12EFB2.h5\")\n\n\n\n\n\n\n\n\nresult_train_model12EFB2\nresult_val_model12EFB2\n\n\n\n\nloss\n0.1245520\n0.1719811\n\n\naccuracy\n0.9593518\n0.9445685\n\n\nauc\n0.9985721\n0.9965881\n\n\n\n\n\nStrata w Model12EFB2 jest na obu zbiorach jest niska, co sugeruje, że model ma nie trudność dopasowywania się do danych. Dokładność na zbiorze testowym wyniosła 95.94%, natomiast na zbiorze walidacyjnym 94.46%, co sugeruje, że model radzi sobie bardzo dobrze z przewidywaniem klas i generalizacją. Wartości AUC są bliskie 1 w obu przypadkach, co oznacza że model ma zdolności do różnicowania klas.\n\n\nWnioski\nModel12EFB2 i Model9EFB2 mają najlepsze metryki, są prawie identyczne(to te same modele, tylko model12EFB2 był trenowany dłużej). Model10EFB2 jest lepszy w klasyfikacji treningowego, jednak dużo słabszy na walidacyjnym."
  },
  {
    "objectID": "index.html#ewaluacja-modeli",
    "href": "index.html#ewaluacja-modeli",
    "title": "LULC Classification",
    "section": "Ewaluacja modeli",
    "text": "Ewaluacja modeli\nDo ewaluacji wybrałem Model3, Model8DN121_2, Model9EFB2, Model10EFB2, Model12EFB2. Oraz zrezygnowałem z metryki AUC, na rzecz metryk top3 oraz top5, czyli procent przypadków, w których prawidłowa klasa znajduje się wśród odpowiednio 3 i 5 najbardziej prawdopodobnych predykcji.\n\n\nCode\ntop3 &lt;- metric_top_k_categorical_accuracy(k=3, name=\"top3\")\ntop5 &lt;- metric_top_k_categorical_accuracy(k=5, name=\"top5\")\nmodel3&lt;- load_model_hdf5(\"/kaggle/input/klastfikacja_palu/tensorflow2/v1/1/model3.h5\", compile=FALSE)\nmodel8DN121_2&lt;- load_model_hdf5(\"/kaggle/input/klastfikacja_palu/tensorflow2/v1/1/model8DN121_2.h5\", compile=FALSE)\nmodel9EFB2&lt;- load_model_hdf5(\"/kaggle/input/klastfikacja_palu/tensorflow2/v1/1/model9EFB2.h5\", compile=FALSE)\nmodel10EFB2&lt;- load_model_hdf5(\"/kaggle/input/klastfikacja_palu/tensorflow2/v1/1/model10EFB2.h5\", compile=FALSE)\nmodel12EFB2&lt;- load_model_hdf5(\"/kaggle/input/klastfikacja_palu/tensorflow2/v1/1/model12EFB2.h5\", compile=FALSE)\nmodel3%&gt;%compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_nadam(),\n  metrics = list(\"acc\", top3, top5)\n)\nmodel8DN121_2%&gt;%compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_nadam(),\n  metrics = list(\"acc\", top3, top5)\n)\nmodel9EFB2%&gt;%compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_nadam(),\n  metrics = list(\"acc\", top3, top5)\n)\nmodel10EFB2%&gt;%compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_nadam(),\n  metrics = list(\"acc\", top3, top5)\n)\nmodel12EFB2%&gt;%compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_nadam(),\n  metrics = list(\"acc\", top3, top5)\n)\nresults_model3&lt;-model3 %&gt;% evaluate(test_generator1)\nresults_model8DN121_2&lt;-model8DN121_2 %&gt;% evaluate(test_generator1)\nresults_model9EFB2&lt;-model9EFB2 %&gt;% evaluate(test_generator1)\nresults_model10EFB2&lt;-model10EFB2 %&gt;% evaluate(test_generator1)\nresults_model12EFB2&lt;-model12EFB2 %&gt;% evaluate(test_generator1)\n\n\n\n\n\n\n\n\nloss\naccuracy\naccuracy-top3\naccuracy-top5\n\n\n\n\nmodel3\n0.3827922\n0.8740741\n0.9833333\n0.9972593\n\n\nmodel8DN121_2\n0.1398813\n0.9514815\n0.9209630\n0.9535185\n\n\nmodel9EFB2\n0.5259916\n0.8111111\n0.9254209\n0.9572727\n\n\nmodel10EFB2\n0.5875942\n0.8040740\n0.9284259\n0.9603704\n\n\nmodel12EFB2\n0.1800205\n0.9355556\n0.9376190\n0.9659259\n\n\n\n\n\n\nWnioski\n\nNajlepszy ogólny model: Model8DN121_2, ze względu na najniższą stratę i najwyższą dokładność, co wskazuje na jego skuteczność i precyzję w klasyfikacji.\nModel3 również jest bardzo dobrym wyborem, szczególnie ze względu na bardzo wysoką dokładność w Top-3 i Top-5, co może być korzystne w scenariuszach, gdzie kluczowa jest rozważana większa liczba najwyższych predykcji.\nModel12EFB2 także jest godny uwagi, wykazuje niską stratę i wysoką dokładność, co czyni go dobrym wyborem, jeśli zależy nam na balansie między dopasowaniem a precyzją.\nModel9EFB2 i Model10EFB2 wykazują wyższe straty i niższą dokładność, więc mogą być mniej skuteczne w porównaniu do pozostałych modeli.\nModel9EFB2 i Model12EFB2 różnią się tylko ilością epok trenowania, co sugeruje, że callback nie pomógł odnaleść optymalnej liczby epok."
  }
]